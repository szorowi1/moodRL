{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mood-RL Behavioral Preprocessing\n",
    "## Extract and organize RL behavior\n",
    "\n",
    "> Participants played three slot machine games, each involving three different slot machines (nine machines overall). Each machine had a distinct colour and a distinct pattern depicted on it, and some fixed probability of yielding reward when chosen. Unbeknownst to participants, within each game these probabilities were always 0.2, 0.4 and 0.6. On each trial, participants chose between two machines that appeared on the screen, and were either rewarded with 25 cents or not rewarded, according to the probability associated with the chosen machine. Participants had 3 s to make their choice. Each game consisted of 42 trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pandas import DataFrame, concat\n",
    "from scipy.io import loadmat\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters.\n",
    "raw_dir = 'raw'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Locate files.\n",
    "files = sorted(os.listdir(raw_dir)) \n",
    "\n",
    "df = []\n",
    "for f in files:\n",
    "    \n",
    "    ## Load and extract data.\n",
    "    mat = loadmat(os.path.join(raw_dir, f))\n",
    "    data = mat['Data'].squeeze()\n",
    "    \n",
    "    ## Extract subject/datetime info.\n",
    "    subject = subject, date, time = f.replace('.mat','').split('_')\n",
    "    date = '-'.join(['%0.2d' %int(s) for s in date.split('-')])\n",
    "    time = '-'.join(['%0.2d' %int(s) for s in time.split('-')])\n",
    "    dt = datetime.strptime('%s %s' %(date,time), '%Y-%m-%d %H-%M-%S')\n",
    "    \n",
    "    ## Iterate over blocks.\n",
    "    for blockno, block in enumerate(data):\n",
    "\n",
    "        ## Separate data categories\n",
    "        ## ------------------------\n",
    "        ## - outcome: binary array indicating win (1) or loss (0).\n",
    "        ## - onsets: list of arrays with task event onsets.\n",
    "        ## - choice: integer array indicating machine chosen.\n",
    "        ## - ratings: list of arrays with mood/probability ratings.\n",
    "        ## - info: list of arrays of block information.\n",
    "        outcome, onsets, choice, ratings, info = block\n",
    "\n",
    "        ## Define machine identities\n",
    "        ## -------------------------\n",
    "        ## Machine stimulus and outcome probability are counterbalanced\n",
    "        ## across participants. In the mat files, machines are labelled\n",
    "        ## according to their stimulus, not their outcome probability.\n",
    "        ## This section of code inverts this (i.e. identifies machine\n",
    "        ## by outcome probability). This ultimately results in the \n",
    "        ## categorization scheme:\n",
    "        ## - 20% probability = machines [1, 4, 7]\n",
    "        ## - 40% probability = machines [2, 5, 8]\n",
    "        ## - 60% probability = machines [3, 6, 9]\n",
    "        _, presentation, identities = [arr.squeeze() for arr in info.squeeze().tolist()]\n",
    "        if blockno < 3: identities += blockno * identities.size\n",
    "        else: identities += np.repeat(np.arange(0,9,3),3).astype(identities.dtype)\n",
    "        M1, M2 = identities[presentation-1]  \n",
    "\n",
    "        ## Compute reaction times\n",
    "        ## ----------------------\n",
    "        ## Reaction times are simply computed from the onsets data.\n",
    "        ## The second and third rows of the onsets matrix are\n",
    "        ## stimulus and response onsets, respectively. Subtracting\n",
    "        ## the second from the first returns the reaction time.\n",
    "        onsets = np.array(onsets.squeeze().tolist()[:5]).squeeze()\n",
    "        RT = onsets[2] - onsets[1]\n",
    "            \n",
    "        ## Compute outcome\n",
    "        ## ---------------\n",
    "        ## Outcome is already a binary vector (win = 1, lose = 0).\n",
    "        ## This is simply multiplied by 0.25 for Blocks 1-3, and \n",
    "        ## by 0.50 for Blocks 4. \n",
    "        if blockno < 3: outcome = outcome * 0.25\n",
    "        else: outcome = outcome * 0.50\n",
    "        \n",
    "        ## Assemble DataFrame\n",
    "        ## ------------------\n",
    "        ## Stores the following information: subject ID, block number, \n",
    "        ## trial number, machine 1/2, choice, reaction time, outcome.\n",
    "        d = dict(Subject = np.repeat(subject, RT.size),\n",
    "                 Datetime = np.repeat(dt, RT.size),\n",
    "                 Block = np.repeat(blockno+1, RT.size),\n",
    "                 Trial = np.arange(RT.size)+1,\n",
    "                 M1 = M1, M2 = M2, Choice = choice.squeeze(),\n",
    "                 RT = RT, Outcome = outcome.squeeze())\n",
    "        df.append(DataFrame(d, columns=('Subject','Datetime','Block','Trial',\n",
    "                                        'M1','M2','Choice','RT','Outcome')))\n",
    "\n",
    "## Concatenate DataFrames.\n",
    "df = concat(df)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Postprocessing.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Handle missing data\n",
    "## -------------------\n",
    "## Missing choices and reaction times are set to NaNs. \n",
    "df.Choice = np.where(df.Choice==0, np.nan, np.where(df.Choice==1, df.M1, df.M2))\n",
    "df.RT = np.where(df.Choice.isnull(), np.nan, df.RT)\n",
    "\n",
    "## Save.\n",
    "df.to_csv('moodRL_data.csv', index=False)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and organize mood ratings.\n",
    "\n",
    "> After the 7th, 21st and 35th trials, participants responded to the question '*how do you feel right now?*', by choosing one out of a series of figures whose face varied from unhappy to happy (the self-assessment manikin). After the 14th, 28th and 42nd trials, participants were asked to estimate how likely each of the three slot machines in the current game was to yield reward, between 0 and 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pandas import DataFrame, concat\n",
    "from scipy.io import loadmat\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters.\n",
    "raw_dir = 'raw'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Locate files.\n",
    "files = sorted(os.listdir(raw_dir)) \n",
    "\n",
    "df = []\n",
    "for f in files:\n",
    "    \n",
    "    ## Load and extract data.\n",
    "    mat = loadmat(os.path.join(raw_dir, f))\n",
    "    data = mat['Data'].squeeze()\n",
    "    \n",
    "    ## Extract subject/datetime info.\n",
    "    subject = subject, date, time = f.replace('.mat','').split('_')\n",
    "    date = '-'.join(['%0.2d' %int(s) for s in date.split('-')])\n",
    "    time = '-'.join(['%0.2d' %int(s) for s in time.split('-')])\n",
    "    dt = datetime.strptime('%s %s' %(date,time), '%Y-%m-%d %H-%M-%S')\n",
    "    \n",
    "    ## Iterate over blocks.\n",
    "    for blockno, block in enumerate(data[:-1]):\n",
    "\n",
    "        ## Separate data categories\n",
    "        ## ------------------------\n",
    "        ## - outcome: binary array indicating win (1) or loss (0).\n",
    "        ## - onsets: list of arrays with task event onsets.\n",
    "        ## - choice: integer array indicating machine chosen.\n",
    "        ## - ratings: list of arrays with mood/probability ratings.\n",
    "        ## - info: list of arrays of block information.\n",
    "        outcome, onsets, choice, ratings, info = block\n",
    "        \n",
    "        ## Organize ratings\n",
    "        ## ----------------\n",
    "        ## Mood and probability ratings are queried on the (7, 21, 35) and \n",
    "        ## (14, 28, 42) trial respectively. Probability judgments are \n",
    "        ## re-sorted by objective probability of reward in ascending order. \n",
    "        _, _, identities = [arr.squeeze() for arr in info.squeeze().tolist()]\n",
    "        _, _, moods, probabilities = ratings.squeeze().tolist()\n",
    "        probabilities = probabilities[:,identities-1]\n",
    "        \n",
    "        ## Merge ratings.\n",
    "        trials = [7, 21, 35] + [14, 28, 42] * 3\n",
    "        ratings = np.concatenate([moods.squeeze(), probabilities.flatten(order='F')])\n",
    "        variables = np.repeat(np.arange(1+3*blockno,4+3*blockno), 3)\n",
    "        variables = np.concatenate([np.repeat('Mood',3), variables])\n",
    "        \n",
    "        ## Assemble DataFrame\n",
    "        ## ------------------\n",
    "        ## Stores the following information: subject ID, datetime, \n",
    "        ## block number, rating type, trial number, rating.\n",
    "        d = dict(Subject = np.repeat(subject, ratings.size),\n",
    "                 Datetime = np.repeat(dt, ratings.size),\n",
    "                 Block = np.repeat(blockno+1, ratings.size),\n",
    "                 Trial = trials,\n",
    "                 Variable = variables, \n",
    "                 Rating = ratings)\n",
    "        df.append(DataFrame(d, columns=('Subject','Datetime','Block','Trial',\n",
    "                                        'Variable','Rating')))\n",
    "\n",
    "## Concatenate DataFrames.\n",
    "df = concat(df)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Postprocessing.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Re-sort by trial.\n",
    "df = df.sort_values(['Subject','Datetime','Block','Trial'])\n",
    "\n",
    "## Save.\n",
    "df.to_csv('moodRL_ratings.csv', index=False)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and organize metadata.\n",
    "> All participants filled out the international personality item pool (IPIP) version of the HPS. In addition, to mitigate a possible recency effect on choices in the final test game, we separated in time the second and third games, as well as the third and test games, by having participants fill out additional questionnaires, whose results were not analysed. These included the BIS/BAS scales, and the IPIP version of the NEO Personality Inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pandas import DataFrame, Series, read_csv\n",
    "from scipy.io import loadmat\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters.\n",
    "raw_dir = 'raw'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Locate files.\n",
    "files = sorted(os.listdir(raw_dir)) \n",
    "\n",
    "metadata = []\n",
    "for f in files:\n",
    "    \n",
    "    ## Load data.\n",
    "    mat = loadmat(os.path.join(raw_dir, f))\n",
    "    \n",
    "    ## Extract subject/datetime info.\n",
    "    subject = subject, date, time = f.replace('.mat','').split('_')\n",
    "    date = '-'.join(['%0.2d' %int(s) for s in date.split('-')])\n",
    "    time = '-'.join(['%0.2d' %int(s) for s in time.split('-')])\n",
    "    dt = datetime.strptime('%s %s' %(date,time), '%Y-%m-%d %H-%M-%S')\n",
    "    \n",
    "    ## Initialize Series object\n",
    "    ## ------------------------\n",
    "    ## In this first step, a Pandas Series object is initialized with the \n",
    "    ## following information: subject ID, datetime, eyetracking recorded, \n",
    "    ## fMRI recorded, Wheel of Fortune outcome.\n",
    "    scan = int(mat['scan'])\n",
    "    eyetrack = int(mat['eyetrack'])\n",
    "    WoF = float(mat['WOF'].squeeze().tolist()[0])\n",
    "    series = Series([subject,dt,scan,eyetrack,WoF], \n",
    "                    index=('Subject','Datetime','Scan','Eyetrack','WoF'))\n",
    "    \n",
    "    ## Extract and store survey data\n",
    "    ## -----------------------------\n",
    "    ## In this step, the survey information is extracted from the Matlab\n",
    "    ## object and stored in the Series. Information is subdivided by \n",
    "    ## survey scale. \n",
    "    for data, survey in zip(mat['Rt'].squeeze().tolist(), mat['Rt'].dtype.names):\n",
    "\n",
    "        ## Extract subscale names/data.\n",
    "        scales = data.dtype.names\n",
    "        data = np.array(data.squeeze().tolist()).squeeze()\n",
    "        if survey == 'mood': scales = ['1','2']\n",
    "            \n",
    "        ## Iteratively store.\n",
    "        for datum, scale in zip(data, scales):\n",
    "            series['%s_%s' %(survey,scale)] = datum\n",
    "    \n",
    "    ## Append series object.\n",
    "    metadata.append(series)\n",
    "    \n",
    "## Concatenate Series objects.\n",
    "metadata = DataFrame(metadata)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Postprocessing.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Calculate earnings\n",
    "## ------------------\n",
    "## Total earnings are calculated based on the summed total outcomes\n",
    "## of the reinforcement learning task (Blocks 1-3) and machine \n",
    "## discrimination task (Block 4), and the outcome on the Wheel of\n",
    "## Fortune task. The former are calculated from the RL data spreadsheet.\n",
    "data = read_csv('moodRL_data.csv')\n",
    "outcomes = data.groupby('Datetime').Outcome.sum()\n",
    "metadata.insert(4, 'Outcomes', outcomes.as_matrix())\n",
    "metadata.insert(6, 'Earnings', metadata.WoF + metadata.Outcomes)\n",
    "\n",
    "## Save.\n",
    "metadata.to_csv('moodRL_metadata.csv', index=False)\n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {},
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
